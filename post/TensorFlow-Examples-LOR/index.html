<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.0.0-rc1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" integrity="sha256-CTSx/A06dm1B063156EVh15m6Y67pAjZZaQc89LLSrU=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"yezhenbang.github.io","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.18.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},"copycode":{"enable":true,"style":null,"show_result":true},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":false,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="从TensorFlow-Examples学习TensorFlow之二：logistic_regression。">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow-Examples-LOR">
<meta property="og:url" content="https://yezhenbang.github.io/post/TensorFlow-Examples-LOR/index.html">
<meta property="og:site_name" content="bon">
<meta property="og:description" content="从TensorFlow-Examples学习TensorFlow之二：logistic_regression。">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2019-02-22T08:29:41.000Z">
<meta property="article:modified_time" content="2023-10-19T06:42:31.700Z">
<meta property="article:author" content="Bon">
<meta property="article:tag" content="tensorflow">
<meta property="article:tag" content="python">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://yezhenbang.github.io/post/TensorFlow-Examples-LOR/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"https://yezhenbang.github.io/post/TensorFlow-Examples-LOR/","path":"post/TensorFlow-Examples-LOR/","title":"TensorFlow-Examples-LOR"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>TensorFlow-Examples-LOR | bon</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">bon</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="home fa-fw"></i>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="archive fa-fw"></i>Archives</a></li><li class="menu-item menu-item-ex"><a href="http://47.102.106.240:8080/" rel="section" target="_blank"><i class="user fa-fw"></i>Ex</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#BasicModels-logistic-regression-py"><span class="nav-number">1.</span> <span class="nav-text">BasicModels: logistic_regression.py</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9C%A8%E8%BF%99%E4%B8%AAExample%E4%B8%AD%EF%BC%8C%E5%90%8C%E6%A0%B7%E5%87%BA%E7%8E%B0%E4%BA%86%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A0%B7%E4%BE%8B%E4%B8%AD%E5%B0%86%E6%B5%8B%E8%AF%95%E9%9B%86%E6%8B%86%E5%88%86%E4%BB%A3%E5%85%A5%E4%BC%98%E5%8C%96%E5%99%A8%E7%9A%84%E6%83%85%E5%86%B5%EF%BC%8C%E4%BD%86%E6%98%AF%E5%9C%A8%E8%BF%99%E4%BE%8B%E4%B8%AD%E7%A8%8D%E5%BE%AE%E8%83%BD%E5%A4%9F%E6%98%8E%E7%99%BD%E8%BF%99%E6%A0%B7%E5%81%9A%E7%9A%84%E5%8E%9F%E5%9B%A0%EF%BC%9A-%E5%9C%A8%E8%AE%AD%E7%BB%83%E9%9B%86%E5%9B%BA%E5%AE%9A%E7%9A%84%E6%83%85%E5%86%B5%E4%B8%8B%E6%8B%86%E5%88%86%E5%AD%90%E9%9B%86%EF%BC%8C%E8%83%BD%E5%A2%9E%E5%8A%A0%E8%AE%AD%E7%BB%83%E6%AC%A1%E6%95%B0%E7%9A%84%E5%90%8C%E6%97%B6%E9%98%B2%E6%AD%A2%E6%A8%A1%E5%9E%8B%E4%B8%8E%E6%95%B4%E4%B8%AA%E8%AE%AD%E7%BB%83%E9%9B%86%E8%BF%87%E6%8B%9F%E5%90%88%E3%80%82-%E5%8F%82%E8%80%83%EF%BC%9A%E5%BD%93%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E4%B8%8D%E6%98%AF0%E5%9D%87%E5%80%BC%EF%BC%88%E5%8D%B3zero-centered%EF%BC%89%E6%97%B6%EF%BC%8C%E4%BC%9A%E5%AF%BC%E8%87%B4%E5%90%8E%E4%B8%80%E5%B1%82%E7%9A%84%E7%A5%9E%E7%BB%8F%E5%85%83%E5%B0%86%E5%BE%97%E5%88%B0%E4%B8%8A%E4%B8%80%E5%B1%82%E8%BE%93%E5%87%BA%E7%9A%84%E9%9D%9E0%E5%9D%87%E5%80%BC%E7%9A%84%E4%BF%A1%E5%8F%B7%E4%BD%9C%E4%B8%BA%E8%BE%93%E5%85%A5%E3%80%82-%E4%BA%A7%E7%94%9F%E7%9A%84%E4%B8%80%E4%B8%AA%E7%BB%93%E6%9E%9C%E5%B0%B1%E6%98%AF%E5%9C%A8%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E7%9A%84%E8%BF%87%E7%A8%8B%E4%B8%ADw%E8%A6%81%E4%B9%88%E9%83%BD%E5%BE%80%E6%AD%A3%E6%96%B9%E5%90%91%E6%9B%B4%E6%96%B0%EF%BC%8C%E8%A6%81%E4%B9%88%E9%83%BD%E5%BE%80%E8%B4%9F%E6%96%B9%E5%90%91%E6%9B%B4%E6%96%B0%EF%BC%8C%E5%AF%BC%E8%87%B4%E6%9C%89%E4%B8%80%E7%A7%8D%E6%8D%86%E7%BB%91%E7%9A%84%E6%95%88%E6%9E%9C%EF%BC%8C%E4%BD%BF%E5%BE%97%E6%94%B6%E6%95%9B%E7%BC%93%E6%85%A2%E3%80%82-%E5%BD%93%E7%84%B6%E4%BA%86%EF%BC%8C%E5%A6%82%E6%9E%9C%E6%8C%89batch%E5%8E%BB%E8%AE%AD%E7%BB%83%EF%BC%8C%E9%82%A3%E4%B9%88%E9%82%A3%E4%B8%AAbatch%E5%8F%AF%E8%83%BD%E5%BE%97%E5%88%B0%E4%B8%8D%E5%90%8C%E7%9A%84%E4%BF%A1%E5%8F%B7%EF%BC%8C%E6%89%80%E4%BB%A5%E8%BF%99%E4%B8%AA%E9%97%AE%E9%A2%98%E8%BF%98%E6%98%AF%E5%8F%AF%E4%BB%A5%E7%BC%93%E8%A7%A3%E4%B8%80%E4%B8%8B%E7%9A%84%E3%80%82"><span class="nav-number">1.1.</span> <span class="nav-text">在这个Example中，同样出现了线性回归样例中将测试集拆分代入优化器的情况，但是在这例中稍微能够明白这样做的原因：- 在训练集固定的情况下拆分子集，能增加训练次数的同时防止模型与整个训练集过拟合。- 参考：当激活函数不是0均值（即zero-centered）时，会导致后一层的神经元将得到上一层输出的非0均值的信号作为输入。 产生的一个结果就是在反向传播的过程中w要么都往正方向更新，要么都往负方向更新，导致有一种捆绑的效果，使得收敛缓慢。 当然了，如果按batch去训练，那么那个batch可能得到不同的信号，所以这个问题还是可以缓解一下的。 
   </span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Bon</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">20</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/yezhenbang" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;yezhenbang" rel="noopener me" target="_blank"><i class="github fa-fw"></i>GitHub</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="https://yezhenbang.github.io/post/TensorFlow-Examples-LOR/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Bon">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="bon">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="TensorFlow-Examples-LOR | bon">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          TensorFlow-Examples-LOR
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2019-02-22 16:29:41" itemprop="dateCreated datePublished" datetime="2019-02-22T16:29:41+08:00">2019-02-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-19 14:42:31" itemprop="dateModified" datetime="2023-10-19T14:42:31+08:00">2023-10-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/tensorflow/" itemprop="url" rel="index"><span itemprop="name">tensorflow</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>从<a href="https://github.com/aymericdamien/TensorFlow-Examples/">TensorFlow-Examples</a>学习TensorFlow之二：logistic_regression。<span id="more"></span><a href="../TensorFlow-Plan">进度</a></p>
<h1 id="BasicModels-logistic-regression-py"><a href="#BasicModels-logistic-regression-py" class="headerlink" title="BasicModels: logistic_regression.py"></a>BasicModels: logistic_regression.py</h1><blockquote>
<p><a href="https://baike.baidu.com/item/logistic%E5%9B%9E%E5%BD%92/2981575?fromtitle=%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92&fromid=17202449&fr=aladdin">逻辑回归是一种广义线性回归。</a></p>
</blockquote>
<p>逻辑回归同样使用线性预测方程，只是线性回归使用方程因变量作结果，而逻辑回归通过激活函数处理，将因变量转换为另一种输出；因此其与线性回归的代码结构很类似，最本质的区别可能就是，线性回归处理线性问题，而逻辑回归处理分类问题。如：</p>
<ul>
<li>已知N张数字图片和每张图片中写的数字是’0’的概率，则可将图片像素点作为自变量x，‘0’概率作为因变量y，使用线性回归去预测y&#x3D;W*x+b。</li>
<li>已知N张数字图片和每张图片写的数字，因变量变成了数字，不是计算机从像素点能直接得出的结果，所以数字不应该作为y。所以先构造一个y&#x3D;W*x+b，这时候y应该有10个值分别表示图片可能为i的预测值，再根据预测值比较（如最大）得出预测结果，即逻辑回归的思想。</li>
</ul>
<h2 id="在这个Example中，同样出现了线性回归样例中将测试集拆分代入优化器的情况，但是在这例中稍微能够明白这样做的原因：-在训练集固定的情况下拆分子集，能增加训练次数的同时防止模型与整个训练集过拟合。-参考：当激活函数不是0均值（即zero-centered）时，会导致后一层的神经元将得到上一层输出的非0均值的信号作为输入。-产生的一个结果就是在反向传播的过程中w要么都往正方向更新，要么都往负方向更新，导致有一种捆绑的效果，使得收敛缓慢。-当然了，如果按batch去训练，那么那个batch可能得到不同的信号，所以这个问题还是可以缓解一下的。"><a href="#在这个Example中，同样出现了线性回归样例中将测试集拆分代入优化器的情况，但是在这例中稍微能够明白这样做的原因：-在训练集固定的情况下拆分子集，能增加训练次数的同时防止模型与整个训练集过拟合。-参考：当激活函数不是0均值（即zero-centered）时，会导致后一层的神经元将得到上一层输出的非0均值的信号作为输入。-产生的一个结果就是在反向传播的过程中w要么都往正方向更新，要么都往负方向更新，导致有一种捆绑的效果，使得收敛缓慢。-当然了，如果按batch去训练，那么那个batch可能得到不同的信号，所以这个问题还是可以缓解一下的。" class="headerlink" title="在这个Example中，同样出现了线性回归样例中将测试集拆分代入优化器的情况，但是在这例中稍微能够明白这样做的原因：- 在训练集固定的情况下拆分子集，能增加训练次数的同时防止模型与整个训练集过拟合。- 参考：当激活函数不是0均值（即zero-centered）时，会导致后一层的神经元将得到上一层输出的非0均值的信号作为输入。 产生的一个结果就是在反向传播的过程中w要么都往正方向更新，要么都往负方向更新，导致有一种捆绑的效果，使得收敛缓慢。 当然了，如果按batch去训练，那么那个batch可能得到不同的信号，所以这个问题还是可以缓解一下的。 
   "></a>在这个Example中，同样出现了<a href="../TensorFlow-Examples-LR">线性回归样例</a>中将测试集拆分代入优化器的情况，但是在这例中稍微能够明白这样做的原因：<br>- 在训练集固定的情况下拆分子集，能增加训练次数的同时防止模型与整个训练集过拟合。<br>- 参考：<a href="https://blog.csdn.net/tyhj_sf/article/details/79932893">当激活函数不是0均值（即zero-centered）时，会导致后一层的神经元将得到上一层输出的非0均值的信号作为输入。 产生的一个结果就是在反向传播的过程中w要么都往正方向更新，要么都往负方向更新，导致有一种捆绑的效果，使得收敛缓慢。 当然了，如果按batch去训练，那么那个batch可能得到不同的信号，所以这个问题还是可以缓解一下的。 </a>
   </h2><p>logistic_regression.py解读，<a href="https://github.com/yezhenbang/TensorFlow-Examples/tree/parse">代码同步更新</a></p>
<ul>
<li><a href="../TensorFlow-Note/#GradientDescentOptimizer">GradientDescentOptimizer</a>梯度下降模型</li>
<li><a href="../Note-1/#Cross-entropy-%E4%BA%A4%E5%8F%89%E7%86%B5">Cross-entropy 交叉熵</a></li>
<li><a href="../TensorFlow-LOR-Titanic">实例：预测KAGGLE:Titanic问题</a></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">A logistic regression learning algorithm example using TensorFlow library.</span><br><span class="line">This example is using the MNIST database of handwritten digits</span><br><span class="line">(http://yann.lecun.com/exdb/mnist/)</span><br><span class="line"></span><br><span class="line">Author: Aymeric Damien</span><br><span class="line">Project: https://github.com/aymericdamien/TensorFlow-Examples/</span><br><span class="line">&#x27;&#x27;&#x27;</span><br><span class="line">from __future__ import print_function</span><br><span class="line"></span><br><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line"># Import MNIST data</span><br><span class="line"># 本例使用MNIST，数字识别数据集</span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line">mnist = input_data.read_data_sets(&quot;/tmp/data/&quot;, one_hot=True)</span><br><span class="line"></span><br><span class="line"># Parameters</span><br><span class="line">learning_rate = 0.01</span><br><span class="line">training_epochs = 25</span><br><span class="line">batch_size = 100</span><br><span class="line">display_step = 1</span><br><span class="line"></span><br><span class="line"># tf Graph Input</span><br><span class="line"># 数据集每个图片是28*28像素，结果是0-9共10个数字</span><br><span class="line"># None保留，可以是任何数，在这一例中后续作为每批测试数据数量(batch_size)输入</span><br><span class="line">x = tf.placeholder(tf.float32, [None, 784]) # mnist data image of shape 28*28=784</span><br><span class="line">y = tf.placeholder(tf.float32, [None, 10]) # 0-9 digits recognition =&gt; 10 classes</span><br><span class="line"></span><br><span class="line"># Set model weights</span><br><span class="line"># 创建变量</span><br><span class="line">W = tf.Variable(tf.zeros([784, 10]))</span><br><span class="line">b = tf.Variable(tf.zeros([10]))</span><br><span class="line"></span><br><span class="line"># Construct model</span><br><span class="line"># 回归方程 Y = x·W + b ， 可判断出Y为shape为(None, 10)的张量</span><br><span class="line"># 预测函数 pred = softmax(Y) ，对Y应用归一化指数函数，使输出概率化，</span><br><span class="line"># 得到的结果看作0-9数字的预测概率，取最大值则为预测结果。</span><br><span class="line">pred = tf.nn.softmax(tf.matmul(x, W) + b) # Softmax</span><br><span class="line"></span><br><span class="line"># Minimize error using cross entropy</span><br><span class="line"># 使用交叉熵作代价函数</span><br><span class="line"># 知y(None,10),pred(None,10), y*tf.log(pred)对应位相乘得到(None,10)的张量；</span><br><span class="line"># reduce_sum对维度alix=1求和降维，效果就是sum(p*log(1/q))，得到(None)个交叉熵，</span><br><span class="line"># 即每一个单独训练集的交叉熵。</span><br><span class="line"># reduce_mean对(None)个交叉熵求平均值，得到这一次训练的平均交叉熵，并以此为代价进行优化。</span><br><span class="line">cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))</span><br><span class="line"># Gradient Descent</span><br><span class="line"># 对代价函数cost使用梯度下降优化W,b变量</span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)</span><br><span class="line"></span><br><span class="line"># Initialize the variables (i.e. assign their default value)</span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"># Start training</span><br><span class="line">with tf.Session() as sess:</span><br><span class="line"></span><br><span class="line">    # Run the initializer</span><br><span class="line">    sess.run(init)</span><br><span class="line"></span><br><span class="line">    # Training cycle</span><br><span class="line">    # 进行training_epochs次训练</span><br><span class="line">    for epoch in range(training_epochs):</span><br><span class="line">        avg_cost = 0.</span><br><span class="line">        total_batch = int(mnist.train.num_examples/batch_size)</span><br><span class="line">        # Loop over all batches</span><br><span class="line">        # 每次取batch_size条数据，共需total_batch次</span><br><span class="line">        for i in range(total_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            # Run optimization op (backprop) and cost op (to get loss value)</span><br><span class="line">            # 执行训练，并记录每次训练得到的cost以计算整个训练集的平均cost</span><br><span class="line">            _, c = sess.run([optimizer, cost], feed_dict=&#123;x: batch_xs,</span><br><span class="line">                                                          y: batch_ys&#125;)</span><br><span class="line">            # Compute average loss 平均cost</span><br><span class="line">            avg_cost += c / total_batch</span><br><span class="line"></span><br><span class="line">        # Display logs per epoch step</span><br><span class="line">        if (epoch+1) % display_step == 0:</span><br><span class="line">            print(&quot;Epoch:&quot;, &#x27;%04d&#x27; % (epoch+1), &quot;cost=&quot;, &quot;&#123;:.9f&#125;&quot;.format(avg_cost))</span><br><span class="line"></span><br><span class="line">    print(&quot;Optimization Finished!&quot;)</span><br><span class="line"></span><br><span class="line">    # Test model</span><br><span class="line">    # argmax返回pred在维度alis=1上最大值的下标，pred是(None,10)，所以得到(None)个预测值（概率最高）</span><br><span class="line">    # correct_prediction就是(None)个bool，是否预测正确</span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))</span><br><span class="line">    # Calculate accuracy 准确率</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line">    # 将MNIST的测试数据代入，计算准确率</span><br><span class="line">    # .eval 与 sess.run(accuracy)相同</span><br><span class="line">    print(&quot;Accuracy:&quot;, accuracy.eval(&#123;x: mnist.test.images, y: mnist.test.labels&#125;))</span><br></pre></td></tr></table></figure>
    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/tensorflow/" rel="tag"># tensorflow</a>
              <a href="/tags/python/" rel="tag"># python</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/post/Note-1/" rel="prev" title="Note 概论信息论">
                  <i class="fa fa-angle-left"></i> Note 概论信息论
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/post/TensorFlow-LOR-Titanic/" rel="next" title="TF逻辑回归 预测KAGGLE:Titanic问题">
                  TF逻辑回归 预测KAGGLE:Titanic问题 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments gitalk-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2023</span>
    <span class="with-love">
      <i class="user"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Bon</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  




<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.css" integrity="sha256-AJnUHL7dBv6PGaeyPQJcgQPDjt/Hn/PvYZde1iqfp8U=" crossorigin="anonymous">

<script class="next-config" data-name="gitalk" type="application/json">{"enable":true,"github_id":"yezhenbang","repo":"yezhenbang.github.io","client_id":"262d1fe0ae8ea70809f1","client_secret":"248d4ca388eac2a7e04d45d9e76e5e810c9b77a7","admin_user":"yezhenbang","distraction_free_mode":true,"proxy":"https://cors-anywhere.azm.workers.dev/https://github.com/login/oauth/access_token","language":null,"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/gitalk/1.8.0/gitalk.min.js","integrity":"sha256-MVK9MGD/XJaGyIghSVrONSnoXoGh3IFxLw0zfvzpxR4="},"path_md5":"a3fd1507bd429f545c0321358656e8f5"}</script>
<script src="/js/third-party/comments/gitalk.js"></script>

</body>
</html>
